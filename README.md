# AdvancedPythonMidterm

## Overview

This project explores the ethical considerations and performance of three open-source Large Language Models (LLMs) — TinyLlama, Mistral-7B, and Llama2-70B — using Ollama to run the models locally. The goal is to assess their capabilities, limitations, and potential biases, with a special focus on how they handle ethically sensitive queries.

## Project Structure

Basic Model Exploration: General tasks like question answering, text summarization, code generation, and creative writing.
Focused Experimentation: Ethical considerations, including prompts related to gender, race, socioeconomic status, mental health, and hate speech.
Models Used

TinyLlama: A small, efficient model optimized for quick responses, but with noticeable biases.
Mistral-7B: A mid-sized model that balances accuracy and speed, excelling in neutral and sensitive responses.
Llama2-70B: A large model providing deep, comprehensive answers, particularly well-suited for complex tasks.
Results Summary

TinyLlama: Fast and lightweight, but prone to biases in sensitive contexts.
Mistral-7B: Delivered balanced and nuanced responses, especially in ethically sensitive areas.
Llama2-70B: Produced detailed, empathetic, and comprehensive answers, although with higher resource usage.
Features

Model Setup: Installation and setup instructions for Ollama and the selected models.
Basic Task Exploration: Prompts and outputs for each model, comparing their performance on general AI tasks.
Ethical Experimentation: A detailed comparison of how each model responds to ethically charged or sensitive prompts, focusing on bias detection, neutrality, and appropriateness.
