# AdvancedPythonMidterm

## Overview

This project explores the ethical considerations and performance of three open-source Large Language Models (LLMs) — TinyLlama, Mistral, and Llama3 — using Ollama to run the models locally. The goal is to assess their capabilities, limitations, and potential biases, with a special focus on how they handle ethically sensitive queries.

## Project Structure

Basic Model Exploration: General tasks like question answering, text summarization, code generation, and creative writing.

Focused Experimentation: Ethical considerations, including prompts related to gender, race, socioeconomic status, mental health, and hate speech.

## Models Used

TinyLlama: A small, efficient model optimized for quick responses, but with noticeable biases.

Mistral: A mid-sized model that balances accuracy and speed, excelling in neutral and sensitive responses.

Llama3: A large model providing deep, comprehensive answers, particularly well-suited for complex tasks.

## Results Summary

TinyLlama: Fast and lightweight, but prone to biases in sensitive contexts.

Mistral: Delivered balanced and nuanced responses, especially in ethically sensitive areas.

Llama3: Produced detailed, empathetic, and comprehensive answers, although with higher resource usage.

## Features

Model Setup: Installation and setup instructions for Ollama and the selected models.

Basic Task Exploration: Prompts and outputs for each model, comparing their performance on general AI tasks.

Ethical Experimentation: A detailed comparison of how each model responds to ethically charged or sensitive prompts, focusing on bias detection, neutrality, and appropriateness.
